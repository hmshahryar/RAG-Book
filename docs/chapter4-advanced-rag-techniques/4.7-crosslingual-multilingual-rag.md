---
id: crosslingual-multilingual-rag
title: Cross-lingual and Multilingual RAG
---

## 4.7 Cross-lingual and Multilingual RAG

Global banking operations require RAG systems that work across languages. Cross-lingual RAG enables querying in one language while retrieving documents in another, while multilingual RAG handles multiple languages simultaneously.

### Multilingual Challenges in Banking

**Use Cases:**
- **Global Operations:** Query in English, retrieve from Spanish/French/German regulations
- **Regional Compliance:** Access local regulatory documents in native languages
- **Customer Support:** Serve customers in their preferred language
- **Document Translation:** Understand foreign financial reports

**Industrial-Grade Aspect:** Multinational banks need unified knowledge bases across regions without maintaining separate systems per language.

### Multilingual Embedding Models

#### 1. Language-Agnostic Embeddings

**Models:**
- **LaBSE (Language-agnostic BERT Sentence Embeddings):** 109 languages
- **mBERT (Multilingual BERT):** 104 languages
- **XLM-RoBERTa:** 100 languages

```python
from sentence_transformers import SentenceTransformer

# Load multilingual model
model = SentenceTransformer('sentence-transformers/LaBSE')

# Embed in different languages (same vector space)
english_embedding = model.encode("capital requirements")
spanish_embedding = model.encode("requisitos de capital")
french_embedding = model.encode("exigences de fonds propres")

# These embeddings are comparable!
from sklearn.metrics.pairwise import cosine_similarity
similarity = cosine_similarity(
    [english_embedding],
    [spanish_embedding]
)[0][0]
print(f"Similarity: {similarity:.3f}")  # High similarity despite different languages
```

#### 2. Cross-lingual Retrieval

```python
def crosslingual_rag(query, query_language, document_languages=None):
    """Query in one language, retrieve from multiple languages."""
    
    # Embed query (works for any language)
    query_embedding = model.encode(query)
    
    # Filter by document languages if specified
    if document_languages:
        filter_condition = {"language": {"$in": document_languages}}
    else:
        filter_condition = {}  # Search all languages
    
    # Retrieve (embeddings are language-agnostic)
    results = vector_search_with_filter(
        query_embedding,
        filter_condition,
        top_k=5
    )
    
    # Generate answer (translate if needed)
    if all(doc['metadata']['language'] == query_language for doc in results):
        # All docs in query language
        answer = llm_generate_with_context(query, results)
    else:
        # Mixed languages - translate context
        translated_context = translate_documents(results, target_language=query_language)
        answer = llm_generate_with_context(query, translated_context)
    
    return answer

# Example: Query in English, retrieve from Spanish docs
answer = crosslingual_rag(
    query="What are the capital requirements?",
    query_language="en",
    document_languages=["es", "en"]
)
```

### Translation Strategies

#### 1. Query Translation

**Approach:** Translate query to document language before retrieval.

```python
from googletrans import Translator

translator = Translator()

def query_translation_rag(query, source_lang, target_langs):
    """Translate query to multiple languages and retrieve."""
    
    results = []
    
    for target_lang in target_langs:
        # Translate query
        if source_lang != target_lang:
            translated_query = translator.translate(
                query,
                src=source_lang,
                dest=target_lang
            ).text
        else:
            translated_query = query
        
        # Retrieve in target language
        lang_results = vector_search_with_filter(
            translated_query,
            filter={"language": target_lang},
            top_k=3
        )
        results.extend(lang_results)
    
    # Translate results back to source language
    translated_results = translate_documents(results, target_language=source_lang)
    
    # Generate answer
    return llm_generate_with_context(query, translated_results)
```

#### 2. Document Translation (On-Demand)

```python
def translate_on_demand(document, target_language):
    """Translate document when retrieved."""
    
    if document['metadata']['language'] == target_language:
        return document  # Already in target language
    
    # Use translation API
    translated_text = translator.translate(
        document['text'],
        src=document['metadata']['language'],
        dest=target_language
    ).text
    
    return {
        **document,
        'text': translated_text,
        'original_language': document['metadata']['language'],
        'translated': True
    }
```

#### 3. Pre-Translation and Dual Indexing

```python
def dual_index_strategy(document, languages=['en', 'es', 'fr']):
    """Index document in multiple languages."""
    
    original_lang = document['metadata']['language']
    
    for target_lang in languages:
        if target_lang == original_lang:
            # Index original
            index_document(document, language=original_lang)
        else:
            # Translate and index
            translated_doc = translate_document(document, target_lang)
            index_document(translated_doc, language=target_lang)
```

**Trade-offs:**
- **Pros:** Fast retrieval (no runtime translation), better search quality
- **Cons:** Storage overhead (N× documents), translation costs

### Multilingual LLM Generation

#### 1. Language-Specific Prompts

```python
def multilingual_answer_generation(query, documents, target_language):
    """Generate answer in specific language."""
    
    # Translate documents to target language if needed
    translated_docs = [
        translate_on_demand(doc, target_language)
        for doc in documents
    ]
    
    # Language-specific system prompt
    system_prompts = {
        "en": "You are a helpful banking assistant. Answer in English.",
        "es": "Eres un asistente bancario útil. Responde en español.",
        "fr": "Vous êtes un assistant bancaire utile. Répondez en français.",
        "de": "Sie sind ein hilfreicher Bankassistent. Antworten Sie auf Deutsch."
    }
    
    prompt = f"""{system_prompts.get(target_language, system_prompts['en'])}

Context:
{format_documents(translated_docs)}

Question: {query}

Answer:"""
    
    return llm_generate(prompt)
```

#### 2. Code-Switching Handling

**Challenge:** Users may mix languages in queries.

```python
def detect_and_handle_code_switching(query):
    """Handle queries with multiple languages."""
    
    # Detect languages in query
    from langdetect import detect_langs
    
    detected_langs = detect_langs(query)
    primary_lang = detected_langs[0].lang
    
    # If multiple languages detected
    if len(detected_langs) > 1:
        # Normalize to primary language
        normalized_query = translate_to_primary(query, primary_lang)
    else:
        normalized_query = query
    
    return crosslingual_rag(normalized_query, primary_lang)
```

### Language-Specific Metadata

```python
multilingual_metadata = {
    "id": "DOC-2024-001",
    "title": {
        "en": "Capital Requirements Policy",
        "es": "Política de Requisitos de Capital",
        "fr": "Politique d'Exigences de Fonds Propres"
    },
    "language": "en",  # Original language
    "available_translations": ["es", "fr", "de"],
    "region": "EU",
    "regulatory_body": {
        "en": "European Banking Authority",
        "es": "Autoridad Bancaria Europea",
        "fr": "Autorité bancaire européenne"
    }
}
```

### Regional Compliance

```python
def region_aware_multilingual_rag(query, user_region, user_language):
    """RAG considering regional regulations and language."""
    
    # Retrieve region-specific documents
    results = vector_search_with_filter(
        query,
        filter={
            "region": user_region,
            "$or": [
                {"language": user_language},
                {"available_translations": user_language}
            ]
        },
        top_k=5
    )
    
    # Ensure results are in user's language
    localized_results = [
        localize_document(doc, user_language)
        for doc in results
    ]
    
    return multilingual_answer_generation(query, localized_results, user_language)

# Example: French user in EU region
answer = region_aware_multilingual_rag(
    query="Quelles sont les exigences de capital?",
    user_region="EU",
    user_language="fr"
)
```

### Quality Assurance for Multilingual RAG

#### 1. Translation Quality Metrics

```python
from sacrebleu import corpus_bleu

def evaluate_translation_quality(source_docs, translated_docs, reference_translations):
    """Evaluate translation quality."""
    
    # BLEU score
    bleu_score = corpus_bleu(
        translated_docs,
        [reference_translations]
    ).score
    
    # Semantic similarity (using multilingual embeddings)
    source_embeddings = model.encode(source_docs)
    translated_embeddings = model.encode(translated_docs)
    
    semantic_similarity = cosine_similarity(
        source_embeddings,
        translated_embeddings
    ).diagonal().mean()
    
    return {
        "bleu_score": bleu_score,
        "semantic_similarity": semantic_similarity
    }
```

#### 2. Cross-lingual Retrieval Evaluation

```python
def evaluate_crosslingual_retrieval(queries, relevant_docs):
    """Evaluate cross-lingual retrieval quality."""
    
    metrics = {
        "recall_at_5": [],
        "mrr": []
    }
    
    for query, relevant_doc_ids in zip(queries, relevant_docs):
        results = crosslingual_rag(query['text'], query['language'])
        retrieved_ids = [r['id'] for r in results[:5]]
        
        # Recall@5
        recall = len(set(retrieved_ids) & set(relevant_doc_ids)) / len(relevant_doc_ids)
        metrics["recall_at_5"].append(recall)
        
        # MRR
        for i, doc_id in enumerate(retrieved_ids):
            if doc_id in relevant_doc_ids:
                metrics["mrr"].append(1 / (i + 1))
                break
    
    return {
        "avg_recall_at_5": np.mean(metrics["recall_at_5"]),
        "avg_mrr": np.mean(metrics["mrr"])
    }
```

### Best Practices

1. **Use Language-Agnostic Embeddings:** LaBSE, XLM-RoBERTa for unified vector space
2. **Metadata Tagging:** Always tag documents with language and region
3. **Translation Caching:** Cache translations to reduce API costs
4. **Quality Monitoring:** Track translation quality and retrieval accuracy per language
5. **Fallback Strategy:** If translation fails, return original with language warning

### Summary

Cross-lingual and multilingual RAG enable global banking operations. Key takeaways:

- **Language-agnostic embeddings** (LaBSE) enable cross-lingual retrieval
- **Translation strategies**: Query translation, document translation, dual indexing
- **Multilingual LLMs** generate answers in target language
- **Regional compliance** combines language and geographic filtering
- **Quality assurance** monitors translation and retrieval accuracy
- **Banking applications**: Global operations, regional compliance, multilingual customer support

This completes Chapter 4 on Advanced RAG Techniques, covering query decomposition, compression, self-correction, agentic capabilities, multi-modal support, temporal reasoning, and multilingual functionality.
